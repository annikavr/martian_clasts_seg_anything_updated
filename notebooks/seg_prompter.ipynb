{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Iov3yhoRnxG2"
   },
   "source": [
    "Create a `HOME` constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgS8jFPMnj5h",
    "outputId": "b650db3f-5012-46da-a581-821c00f6645f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOME: /home/ec2-user/geoseg/segment-anything/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vlhbd_f4xfiJ"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "t6_9PSZupghA"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda')\n",
    "MODEL_TYPE = \"vit_b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/facebookresearch/segment-anything.git\n",
      "  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-i14qdd2t\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-i14qdd2t\n",
      "  Resolved https://github.com/facebookresearch/segment-anything.git to commit dca509fe793f601edb92606367a655c15ac00fdf\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n41g6y-Zx-9x"
   },
   "outputs": [],
   "source": [
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "chkpt_path = '../weights/sam_vit_b_01ec64.pth'\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=chkpt_path).to(device=DEVICE)\n",
    "\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def process_image(image_path):\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Verify if the image is loaded\n",
    "    if image is None:\n",
    "        print(f'Could not open or find the image: {image_path}')\n",
    "        return None\n",
    "    \n",
    "    # Convert the OpenCV image to a PIL Image for easier manipulation\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    image_final = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    return image_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved results for ZL0_0732_0731938166_896EBY_N0363294ZCAM07114_1100LMJ01.png\n",
      "Processed and saved results for ZL0_0763_0734689015_318EBY_N0380000ZCAM07114_1100LMJ01.png\n",
      "Processed and saved results for ZL0_0764_0734772775_443EBY_N0380944ZCAM07114_1100LMJ03.png\n",
      "Processed and saved results for ZL0_0896_0746497876_285EBY_N0440820ZCAM07114_0340LMJ01.png\n",
      "Processed and saved results for ZL0_0899_0746759154_159EBY_N0440898ZCAM07114_0340LMJ02.png\n",
      "Processed and saved results for ZL0_0950_0751290309_364EBY_N0461870ZCAM07114_0340LMJ01.png\n",
      "Processed and saved results for ZL0_0950_0751290403_363EBY_N0461870ZCAM07114_1100LMJ01.png\n",
      "Processed and saved results for ZL0_1000_0755729009_894EBY_N0474404ZCAM07114_0340LMJ01.png\n",
      "Processed and saved results for ZL0_1000_0755729038_894EBY_N0474404ZCAM07114_1100LMJ01.png\n",
      "Processed and saved results for ZL0_1006_0756258025_456EBY_N0481156ZCAM07114_0340LMJ01.png\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Path to the directories\n",
    "imgs_path = './prompt_imgs'\n",
    "labels_path = './prompt_labels'\n",
    "output_path = './prompt_out'\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Get all image and corresponding JSON label files\n",
    "imgs_files = glob.glob(os.path.join(imgs_path, '*.png'))\n",
    "\n",
    "# Iterate over all images\n",
    "for i, img_file in enumerate(imgs_files):\n",
    "    # Load image\n",
    "    img = cv2.imread(img_file)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Set image for the predictor\n",
    "    predictor.set_image(img)\n",
    "\n",
    "    # Load corresponding JSON file\n",
    "    json_file = os.path.join(labels_path, os.path.basename(img_file).replace('.png', '.json'))\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "        bboxes = data['bboxes']\n",
    "        \n",
    "    original_json = f\"./dataset/{os.path.basename(img_file).replace('.png', '').replace('.json', '')}.json\"\n",
    "    img_metadata = None\n",
    "    with open(original_json, 'r') as original_file:\n",
    "        original_data = json.load(original_file)\n",
    "        img_metadata = original_data['metadata']\n",
    "    # Prepare bounding boxes in batches of 20\n",
    "    input_boxes_batches = []\n",
    "    curr_batch = []\n",
    "    count = 0\n",
    "    for bbox in bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        count += 1\n",
    "        if count != 20:\n",
    "            curr_batch.append([x, y, x + w, y + h])\n",
    "        else:\n",
    "            input_boxes_batches.append(curr_batch)\n",
    "            curr_batch = [[x, y, x + w, y + h]]\n",
    "            count = 1\n",
    "    if curr_batch:  # Add remaining boxes if any\n",
    "        input_boxes_batches.append(curr_batch)\n",
    "\n",
    "    # Process each batch of boxes and generate masks\n",
    "    masks_batches = []\n",
    "    for input_boxes in input_boxes_batches:\n",
    "        tens_boxes = torch.tensor(input_boxes, device=predictor.device)\n",
    "        transformed_boxes = predictor.transform.apply_boxes_torch(tens_boxes, img.shape[:2])\n",
    "        masks, _, _ = predictor.predict_torch(\n",
    "            point_coords=None,\n",
    "            point_labels=None,\n",
    "            boxes=transformed_boxes,\n",
    "            multimask_output=False,\n",
    "        )\n",
    "        masks_batches.append(masks)\n",
    "\n",
    "        # Cleanup to manage GPU memory\n",
    "        del tens_boxes\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    # Collect results\n",
    "    result = []\n",
    "    for masks in masks_batches:\n",
    "        for mask in masks:\n",
    "            result.append(mask.cpu().numpy())\n",
    "\n",
    "    # Convert masks to polygons and prepare JSON\n",
    "    segments = []\n",
    "    for res in result:\n",
    "        # Ensure the mask is a 2D array\n",
    "        if res.ndim > 2:\n",
    "            res = res.squeeze()\n",
    "        if res.ndim == 2 and res.size > 0:\n",
    "            mask = (res.astype(np.uint8) * 255)\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            for contour in contours:\n",
    "                poly = cv2.approxPolyDP(contour, 1, True).reshape(-1, 2).tolist()\n",
    "                if len(poly) < 3:  # Skip invalid polygons\n",
    "                    continue\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                area = cv2.contourArea(contour)\n",
    "                segments.append({\"bbox\": [x, y, w, h], \"polygon\": [poly], \"area\": area})\n",
    "\n",
    "    # Save the metadata as a JSON file\n",
    "    json_path = os.path.join(output_path, f\"{os.path.basename(img_file).replace('.png', '').replace('.json', '')}.json\")\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump({\"segments\": segments, \"metadata\": img_metadata}, f)\n",
    "\n",
    "    print(f\"Processed and saved results for {os.path.basename(img_file)}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003aea4605dc41a0915ced39cec9ae48": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14c3f6ad55bb46708ab8b6b3a77dff4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6dbb804916844860b2215ecf4d3f426c",
       "IPY_MODEL_6c80b3354a4f4084a29484feccae0359",
       "IPY_MODEL_b63e4dbbc4cd41e1b604df2eaa75b556"
      ],
      "layout": "IPY_MODEL_7ee064cfd428488a853a8bfe50888b2f"
     }
    },
    "4c636ae2296443149fa9012ecb74bfc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d1f8932e9da4681800711f5502afe9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c80b3354a4f4084a29484feccae0359": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4c636ae2296443149fa9012ecb74bfc6",
      "max": 375042383,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9e6b657410f4bc4ab63ec67927d50d0",
      "value": 375042383
     }
    },
    "6dbb804916844860b2215ecf4d3f426c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b3a23fdd184a4b5791c02c0c5538ea71",
      "placeholder": "​",
      "style": "IPY_MODEL_003aea4605dc41a0915ced39cec9ae48",
      "value": "Downloading sam_vit_b_01ec64.pth: 100%"
     }
    },
    "7ee064cfd428488a853a8bfe50888b2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3a23fdd184a4b5791c02c0c5538ea71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63e4dbbc4cd41e1b604df2eaa75b556": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1cf1ec7180d43848f03ebeface6273d",
      "placeholder": "​",
      "style": "IPY_MODEL_4d1f8932e9da4681800711f5502afe9f",
      "value": " 375M/375M [00:01&lt;00:00, 342MB/s]"
     }
    },
    "e9e6b657410f4bc4ab63ec67927d50d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f1cf1ec7180d43848f03ebeface6273d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
